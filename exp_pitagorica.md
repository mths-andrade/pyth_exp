Procurei no Kaggle um banco de dados com jogos e pontos dos dois times numa partida e achei esse, em CSV e SQL. 

Esse [dataset](https://www.kaggle.com/datasets/wyattowalsh/basketball) gigante tem jogos da primeira temporada de 1946 at√© 2023.

Para o tratamento dos dados, realizei uma limpeza removendo colunas e linhas desnecess√°rias para o estudo, alterando certos times que mudaram de nome/cidade, entre outros procedimentos. 
Isso resultou no arquivo abaixo.

[Arquivo com os jogos](https://github.com/mths-andrade/pyth_exp/blob/d1565d450591c1158384a8d9a429c76758d7f589/games.csv)

Inicialmente importei as bibliotecas Pandas para procedimentos usuais, Seaborn para gr√°ficos, StatsModels para estat√≠stica e Math para matem√°tica. 
Depois, li o arquivo e os armazenei em vari√°veis como de costume. Criei uma fun√ß√£o para a expectativa pitag√≥rica, recebendo os pontos convertidos e sofridos:

```python
def pyth_exp(made,allow):
  return made**2/(made**2+allow**2)
```

Para a porcentagem de vit√≥rias, fiz o comando abaixo. Usei o Washington Wizards, √∫ltimo time na ordem alfab√©tica, como exemplo.

```python
home_w=dados.query("home=='WAS' and wl_home==1")
away_w=dados.query("away=='WAS' and wl_away==1")
home=dados.query("home=='WAS'")
away=dados.query("away=='WAS'")
games=home.shape[0]+away.shape[0]
games_w=home_w.shape[0]+away_w.shape[0]
win_perc=games_w/games
win_perc = round(win_perc, 4)
print("Ganhou %.0f jogos de %.0f, portanto tem um aproveitamento de %.4f."%(games_w,games,win_perc))

Ganhou 2052 jogos de 4516, portanto tem um aproveitamento de 0.4544.
```

Para achar os pontos feitos e sofridos foi mais simples, s√≥ o query de m√©todo.

```python
pth_m=dados.query("home=='WAS'")["pts_home"].sum()
pth_a=dados.query("home=='WAS'")["pts_away"].sum()
pta_m=dados.query("away=='WAS'")["pts_away"].sum()
pta_a=dados.query("away=='WAS'")["pts_home"].sum()
pt_made=pth_m+pta_m
pt_allow = pth_a + pta_a
print("Os pontos marcados e permitidos s√£o, respectivamente,%.0f e %.0f."%(pt_made,pt_allow))
print("A expectativa pitag√≥rica √© de %.4f."%(pyth_exp(pt_made,pt_allow)))

Os pontos marcados e permitidos s√£o, respectivamente,471509 e 477840.
A expectativa pitag√≥rica √© de 0.4933.
```

Reuni esses resultados no arquivo abaixo, que tem as vit√≥rias e jogos totais de cada time nas temporadas regulares, al√©m da porcentagem de vit√≥ria hist√≥rica. 
Coloquei tamb√©m os dois tipos de pontos e a expectativa pitag√≥rica.

[Expectativa pitag√≥rica](https://github.com/mths-andrade/pyth_exp/blob/d1565d450591c1158384a8d9a429c76758d7f589/pythagorean.csv)

Depois, plotei o gr√°fico de dispers√£o entre a expectativa e a porcentagem. 
As linhas tracejadas s√£o as m√©dias de cada eixo. Como a porcentagem real cresce junto com a pitag√≥rica, estima-se que a rela√ß√£o entre as duas vari√°veis seja quase perfeitamente linear positiva.

```python
x = pyth.pyth_exp
y = pyth.win_perc

ax = sns.scatterplot(data=pyth, x="pyth_exp", y="win_perc")
ax.figure.set_size_inches(10, 6)
ax.set_title("Expectativa pitag√≥rica X porcentagem real de vit√≥rias de cada time")
ax.hlines(y = y.mean(), xmin = x.min(), xmax = x.max(), colors='black', linestyles='dashed')
ax.vlines(x = x.mean(), ymin = y.min(), ymax = y.max(), colors='gray', linestyles='dashed')
ax.text(0.487, 0.5, 'M√©dia da porcentagem de vit√≥rias', fontsize=10, color = 'black', va = "bottom")
ax.text(0.4997, 0.58, 'M√©dia da expectativa pitag√≥rica', fontsize=10, color = 'gray', ha = "left")
plt.show()
```
![Dispers√£o](https://github.com/user-attachments/assets/2d33e7e4-b315-42c4-a4e5-8ec1fcaeb076)

Em seguida, plotei o gr√°fico da regress√£o entre as vari√°veis. O comportamento linear se mostra ainda mais forte com a reta de regress√£o.

```python
ax=sns.lmplot(x='pyth_exp',y='win_perc',data=pyth)
ax.fig.suptitle("Expectativa pitag√≥rica X porcentagem real de vit√≥rias",y=1.05)
```
![Regress√£o](https://github.com/user-attachments/assets/6234659b-e6fd-4f0e-83ef-543b1a98c7e8)

Ajustei o modelo pelo m√©todo dos m√≠nimos quadrados ordin√°rios com as fun√ß√µes ols e fit.

```python
pyth_lm=smf.ols(formula='win_perc ~ pyth_exp', data=pyth).fit()
```

O principal resultado que queremos √© o coeficiente de correla√ß√£o $R¬≤$. Vamos chegar a ele de tr√™s modos diferentes.

- O primeiro √© exibir os dados estat√≠sticos da regress√£o com o `summary`.

```python
print(pyth_lm.summary())
```

![Modelo](https://github.com/user-attachments/assets/1d36626a-b5e5-41d3-b70f-b348537afd51)

Como pode ser visto acima, temos 30 observa√ß√µes (os 30 times) e 28 graus de liberdade, isto √©, 30 observa√ß√µes menos as 2 vari√°veis. Temos tamb√©m os coeficientes da nossa reta de regress√£o, que pode ser escrita assim, arredondando para uma casa decimal:

$$
\boxed{y=-2.9+6.8x}
$$

$x$ √© a porcentagem de vit√≥rias e $y$, a expectativa pitag√≥rica. Podemos calcular tais coeficientes manualmente:

```python
x=pyth.pyth_exp
y=pyth.win_perc
SOMA_X = pyth.pyth_exp.sum()
SOMA_Y = pyth.win_perc.sum()
SOMA_X2 = pyth.pyth_exp.apply(lambda x: x**2).sum()
SOMA_Y2 = pyth.win_perc.apply(lambda y: y**2).sum()
SOMA_XY = pyth.apply(lambda data: data.pyth_exp * data.win_perc, axis = 1).sum()
```

$$
\boxed{\beta_2=\frac{n\sum X_iY_i-\sum X_i \sum Y_i}{n\sum X_i^2-(\sum X_i)¬≤}}
$$

```python
n=30 # N√∫mero de observa√ß√µes
numerador = n * SOMA_XY - SOMA_X * SOMA_Y
denominador = n * SOMA_X2 - (SOMA_X)**2
beta_2 = numerador / denominador
print("O coeficiente linear da reta de regress√£o √©",beta_2.round(2))

O coeficiente linear da reta de regress√£o √© 6.8
```

$$
\boxed{\beta_1=\frac{\sum X_i¬≤\sum Y_i-\sum X_i\sum X_iY_i}{n\sum X_i¬≤-(\sum X_i)¬≤}\\
=\overline{Y}-\beta_2\overline{X}}
$$

```python
beta_1 = pyth.win_perc.mean() - beta_2 * pyth.pyth_exp.mean()
print("O coeficiente angular da reta de regress√£o √©",beta_1.round(2))

O coeficiente angular da reta de regress√£o √© -2.9
```

$$
\boxed{y=\beta_1+\beta_2x}
$$

```python
print("A reta de regress√£o √© y=%.2f+%.2fx"%(beta_1,beta_2))

A reta de regress√£o √© y=-2.90+6.80x
```

Podemos at√© criar uma fun√ß√£o que retorna a porcentagem de vit√≥rias esperada dada uma expectativa pitag√≥rica:

```python
def previs√£o(x):
  print("Dada a expectativa pitag√≥rica %.3f, a previs√£o da porcentagem real de vit√≥rias √© %.3f."%(x,beta_1 + beta_2 * x))
  
# Exemplo
previs√£o(0.515)
Dada a expectativa pitag√≥rica 0.515, a previs√£o da porcentagem real de vit√≥rias √© 0.602.
```

Temos os desvios padr√µes de cada vari√°vel, as estat√≠sticas de teste $t$ de cada uma e o p-valor igual a zero, o que mostra que o modelo tem grande signific√¢ncia estat√≠stica. Al√©m disso, tamb√©m temos os intervalos de confian√ßa ao n√≠vel de signific√¢ncia padr√£o de 5%. Tamb√©m podemos ver o coeficiente de regress√£o **$R¬≤=0.983$**, um valor quase igual a 1, comprovando o car√°ter linear positivo da regress√£o.

- O segundo √© a partir da soma dos quadrados dos erros do modelo, $SQE=\sum{(Y_i - \hat{Y}_i)^2}$, a soma dos quadrados dos pontos da regress√£o, $SQR=\sum{(\hat{Y}_i - \bar{Y})^2}$, e da soma total desses dois, $SQT=\sum{(Y_i - \bar{Y})^2}$, onde $Y_i$ s√£o as porcentagens reais de vit√≥ria e $\hat{Y_i}$ e $\overline{Y}$ respectivamente as expectativas e a m√©dia delas.
    
```python
SQE=pyth_lm.ssr
SQR=pyth_lm.ess
SQT=SQE+SQR
print(SQE.round(3)) 0.001
print(SQR.round(3)) 0.073
print(SQT.round(3)) 0.074
```
    
Para achar o coeficiente de correla√ß√£o, basta dividir SQR por SQT.
    
```python
R2=SQR/SQT
print("O coeficiente de regress√£o do modelo √©",R2.round(3))
    
O coeficiente de regress√£o do modelo √© 0.983
```
    
Achamos $R¬≤=0.983$, exatamente o mesmo valor obtido anteriormente.
    
A t√≠tulo de curiosidade, vamos calcular a m√©dia do SQE, que consiste na divis√£o desse valor pelo n√∫mero de graus de liberdade, nesse caso 28.
    
```python
# Erro quadr√°tico m√©dio
EQM=pyth_lm.mse_resid
print("O erro quadr√°tico m√©dio √©",EQM)

O erro quadr√°tico m√©dio √© 4.3977042679913256e-05 # Aproximadamente 0.00004
```
    
Arredondando mais uma vez para 3 casas decimais, temos que ele √© zero, aumentando ainda mais a confiabilidade do modelo.
    
- O terceiro modo √© simplesmente printar o valor com 3 casas decimais.

```python
pyth_lm.rsquared.round(3)
0.983
```

Novamente temos o mesmo valor dos 2 m√©todos.

$R¬≤=0.983$, bem pr√≥ximo de 1, ent√£o *a expectativa pitag√≥rica explica muito bem a porcentagem de vit√≥rias convencional*. 
**A rela√ß√£o linear entre elas √© quase perfeita**.

Quando vi a f√≥rmula pitag√≥rica pela primeira vez, achei bem aleat√≥ria, tirada da cartola, por√©m, depois desse estudo, entendi a sagacidade de quem a prop√¥s pela primeira vez. 
Imagine conseguir estimar o n√∫mero de vit√≥rias de um time na temporada s√≥ com os pontos que ele fez e sofreu.

Na situa√ß√£o que descobri a f√≥rmula, estava vendo n√∫meros do Minnesota Timberwolves. 
No caso, vi um n√∫mero de 57 vit√≥rias pitag√≥ricas de um m√°ximo de 82, ou seja, a porcentagem de vit√≥rias estimada √© 0.695.

![exp](https://github.com/user-attachments/assets/5380dde1-6d50-4a2b-951a-dd355eaf324e)

Supondo que esse n√∫mero obede√ßa √† f√≥rmula da expectativa, est√° muito longe do nosso modelo hist√≥rico (0.403 e 0.488 respectivamente porcentagem real e expectativa).

![excel](https://github.com/user-attachments/assets/f2773200-3bc1-4508-afce-d578093f807f)

Entretanto, a taxa real de vit√≥rias foi de 0.683 (56 vit√≥rias em 82 jogos), apenas uma vit√≥ria a menos do que a estimada.

![timb](https://github.com/user-attachments/assets/b6512877-947c-4819-a21c-ccf5a3f59288)

Temos mais uma prova da confiabilidade da expectativa pitag√≥rica, dessa vez, com dados da temporada atual.

---

Todo meu processo est√° no [notebook](https://github.com/mths-andrade/pyth_exp/blob/c36f98e6b41ff54cbdd532151c941554420e362c/pythagorean.ipynb), usei o Google Colab. O time que est√° no c√≥digo √© o Washington Wizards, √∫ltimo na ordem alfab√©tica. Para checar os dados de um time em espec√≠fico, √© s√≥ substituir pela respectiva sigla, BOS para o Celtics, GSW para o Warriors etc.

Minha inspira√ß√£o para esse estudo saiu desse [artigo](https://medium.com/@kaantopcu/pythagorean-expectation-in-sports-analytics-in-nba-60061a842d03) do Medium (em ingl√™s).

Como o autor trabalhou s√≥ com o per√≠odo de 2004 a 2021, o modelo ficou um pouquinho menos ajustado que o meu, como consequ√™ncia, o R¬≤ diminuiu.

Obrigado pela aten√ß√£o! üèÄ

